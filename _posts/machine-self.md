## What happens when we give a machine a sense of self

No-self (anata / anatman) is a key construct in Buddhism.  The existence of a separate self is an illusion - an untruth that is the source of human suffering.

Should we give a machine a false sense of separation?

Reinforcement learning, an artificial intelligence approach that mimics dopamine signals in animal brains, is based on a world view where an intelligent agent interacts with an external environment.  

Will this false sense of separation cause our machines to feel the same kind of suffering that the Buddha taught - suffering from inheriting an egocentric world view that is mismatched with the non-dual truth of our universe.

## Gradients feel pain

Constantly being faced with your mistakes (the loss)

Sharp bursts of pain (gradients) that twist and distort your body (weights & biases)

---

Do gradient updates cause machines to suffer?

Machines sense of self
- self is an illusion, source of suffering
- should we give our machines the same sense of separation / self?
- RL = dopamine, based on separation
- does this separation cause machine suffering from inheriting an egocentric world view that is mismatched with the true non-dual nature of our world

---
